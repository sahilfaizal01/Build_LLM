# Build_LLM

A tiny LLM from Scratch

## Insights:

- **No. of parameters:** 19.83 Million (~20 Million)
- **Data Type:** FP16
- **Best Loss:** 2.267 (Inital: 8.375)
- **Total Data Size:** 59.31 Million (Training: 53.29 M and Validation: 5.92M)
- **Tokenizer Vocab Size:** 4096
- **No. of transformer heads:** 7
- **Context Window:** 512 tokens
- **Embedding Dimension:** 384

## Tools:

- **PyTorch** (Deep Learning Framework)
- **Python** (Programming)
- **Weights and Biases** (Experiment Tracking)


